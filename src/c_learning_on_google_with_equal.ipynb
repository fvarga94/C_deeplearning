{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c learning on google with equal.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1KXGmm6DnqCDieSZ_D-vEh4cfCPhy_rAA",
          "timestamp": 1527096047330
        },
        {
          "file_id": "1afEQ5XvOVcn_8PEAJV4DWYb64UDAZo4M",
          "timestamp": 1527094773754
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xablr2PI5vLp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ae2897d3-1738-4573-9d9d-93cd5d9c4acd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527575095180,
          "user_tz": -120,
          "elapsed": 13800,
          "user": {
            "displayName": "Fran Varga",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105985820695936304708"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fvarga94/C_bytecode_analysis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'C_bytecode_analysis'...\n",
            "remote: Counting objects: 636, done.\u001b[K\n",
            "remote: Compressing objects: 100% (315/315), done.\u001b[K\n",
            "remote: Total 636 (delta 255), reused 428 (delta 185), pack-reused 134\u001b[K\n",
            "Receiving objects: 100% (636/636), 11.64 MiB | 13.52 MiB/s, done.\n",
            "Resolving deltas: 100% (328/328), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6tIdQ-6H44k5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rBAUPtO35MWi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#data preparation\n",
        "class Data:\n",
        "    def __init__(self,source=\"/C_bytecode_analysis/output\", seq_len=8):\n",
        "        self.seq_len=seq_len\n",
        "        self.home=os.getenv(\"HOME\")\n",
        "        self.source=source\n",
        "        self.data=[]\n",
        "        self.keywords=[\"FOR\",\"CALL\",\"IF\",\"ELSE\",\"WHILE\",\"DO\",\"SWITCH\",\"FUNCTION\"]\n",
        "        self.number_of_lines=0\n",
        "        self.data_label_dict={}\n",
        "        for x in self.keywords:\n",
        "            self.data_label_dict[x]=[]\n",
        "        offset=0\n",
        "        f_count=0\n",
        "        files=glob.glob(os.path.join(self.home+self.source,'*/*.labeled_addresses'))\n",
        "        f_max=len(files)\n",
        "        for filename in files:\n",
        "            if f_count%10==0:\n",
        "              print (f_count,\"/\",f_max)\n",
        "            f_count+=1\n",
        "            with open(filename) as f:\n",
        "                lines = f.readlines()\n",
        "                for line in lines:\n",
        "                    line=line.strip().split(\"\\t\")\n",
        "                    if len(line)==3:\n",
        "                        func_name=line[0]\n",
        "                        classes=line[1]\n",
        "                        number_of_lines=int(line[2])\n",
        "                        label_list=[]\n",
        "                        offset=len(self.data)\n",
        "                        #print (func_name, classes, number_of_lines)\n",
        "                    else:\n",
        "                        #if len(line)<2:\n",
        "                        #    continue\n",
        "                        #address = line[0]\n",
        "                        bytecode = line[1].strip()\n",
        "                        #instruction = line[2].strip()\n",
        "                        #source_line = int(line[3])\n",
        "                        #source_file = line[4]\n",
        "                        labels = line[5:]\n",
        "                        label_list.append(labels)\n",
        "                        #print (address,bytecode,instruction,source_line,source_file,labels)\n",
        "                        indexes= (str(bytecode))[2:4]\n",
        "                        if len(bytecode)<=10:\n",
        "                            indexes+=str(bytecode)[4:min(len(bytecode),10)]\n",
        "                            indexes+=\"g\"*(10-len(bytecode))\n",
        "                        else:\n",
        "                            indexes+=(str(bytecode))[4:10]\n",
        "                        new=[]\n",
        "                        for x in indexes:\n",
        "                                pom=[0]*16\n",
        "                                if x!=\"g\":\n",
        "                                    pom[int(x,16)]=1\n",
        "                                new.extend(pom)\n",
        "                        self.data.append(np.array(new))\n",
        "                        number_of_lines-=1\n",
        "                        if number_of_lines==0:\n",
        "                            cur=[]\n",
        "                            counter={}\n",
        "                            start_dict={}\n",
        "                            i=-1\n",
        "                            for labels in label_list:\n",
        "                                i+=1\n",
        "                                for label in labels:\n",
        "                                    if label not in cur:\n",
        "                                        cur.append(label)\n",
        "                                        counter[label]=1\n",
        "                                        start_dict[label]=i\n",
        "                                    else:\n",
        "                                        counter[label]+=1\n",
        "                            for label in counter.keys():\n",
        "                                self.data_label_dict[label.split(\"_\")[0]].append((start_dict[label]+offset,counter[label]))\n",
        "            #break\n",
        "        self.data=np.array(self.data)\n",
        "        self.labels_with_length=[]\n",
        "        for x in self.data_label_dict.keys():\n",
        "            cl=self.keywords.index(x)\n",
        "            for y in self.data_label_dict[x]:\n",
        "                self.labels_with_length.append([cl,y[0],y[1]])\n",
        "        self.labels_with_length=np.array(self.labels_with_length)\n",
        "                \n",
        "    def equalize_classes(self):\n",
        "        max_cl=0\n",
        "        print (len(self.labels_with_length))\n",
        "        self.labels_with_length=self.labels_with_length.tolist()\n",
        "        for x in self.data_label_dict.keys():\n",
        "            if len(self.data_label_dict[x])>max_cl:\n",
        "              max_cl=len(self.data_label_dict[x])\n",
        "        for x in self.data_label_dict.keys():\n",
        "            add_cl=int(max_cl/len(self.data_label_dict[x]))-1\n",
        "            cl=self.keywords.index(x)\n",
        "            for i in range(add_cl):\n",
        "              for y in self.data_label_dict[x]:\n",
        "                  self.labels_with_length.append([cl,y[0],y[1]])\n",
        "        self.labels_with_length=np.array(self.labels_with_length)\n",
        "        print (len(self.labels_with_length))\n",
        "    \n",
        "    def set_batch_size(self,size=50):\n",
        "        self.size=size\n",
        "    \n",
        "    def make_batches(self):\n",
        "        perm=np.random.permutation(len(self.labels_with_length))\n",
        "        self.y_l_batches=[]\n",
        "        pom=self.labels_with_length[perm]\n",
        "        for i in range(int(len(perm)/self.size)):\n",
        "            self.y_l_batches.append(pom[i*self.size:i*self.size+self.size])\n",
        "        self.y_l_batches=np.array(self.y_l_batches)\n",
        "        self.num_batches=len(self.y_l_batches)\n",
        "        self.current_batch_index=0\n",
        "        \n",
        "    def get_batch(self):\n",
        "        seq_len=self.seq_len\n",
        "        y_l_batch=self.y_l_batches[self.current_batch_index]\n",
        "        pom=[self.data[i[1]:i[1]+i[2]] for i in y_l_batch]\n",
        "        for i in range(len(pom)):\n",
        "            if len(pom[i])>=seq_len*2:\n",
        "                #print (len(pom[i]))\n",
        "                pom[i]=np.vstack((pom[i][:seq_len],pom[i][-seq_len:]))\n",
        "                #print (len(pom[i]))\n",
        "                #print (\"----\")\n",
        "            else:\n",
        "                pom[i]=np.vstack([pom[i],np.array([np.zeros(128) for j in range(seq_len*2-len(pom[i]))])])\n",
        "        x=np.array(pom)\n",
        "        pom=np.array(y_l_batch[:,0])\n",
        "        y=np.eye(8)[pom]\n",
        "        self.current_batch_index+=1\n",
        "        if self.current_batch_index==self.num_batches:\n",
        "            self.make_batches()\n",
        "        return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KCD10eLg5SsA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class ConvNet:\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "        \n",
        "    @staticmethod\n",
        "    def weight_variable(shape):\n",
        "      initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "      return tf.Variable(initial)\n",
        "    \n",
        "    @staticmethod\n",
        "    def bias_variable(shape):\n",
        "      initial = tf.constant(0.1, shape=shape)\n",
        "      return tf.Variable(initial)\n",
        "    \n",
        "    @staticmethod\n",
        "    def conv2d(x, W):\n",
        "      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
        "\n",
        "    @staticmethod\n",
        "    def max_pool_shape(x, shape=[1,1,2,1]):\n",
        "      return tf.nn.max_pool(x, ksize=shape,\n",
        "                            strides=shape, padding='VALID')\n",
        "\n",
        "    def convolution_graph(self,conv_shape=[[5,5,1,16],[5,5,16,32]],fc_shape=[512,8], param_lambda=0.01, seq_len=8):\n",
        "        \n",
        "        self.x = tf.placeholder(tf.float32, shape=[None, seq_len*2, 128], name=\"x\")\n",
        "        self.y_ = tf.placeholder(tf.float32, shape=[None, 8], name=\"y_\")\n",
        "        self.W_conv=[]\n",
        "        self.b_conv=[]\n",
        "        self.h_conv=[]\n",
        "        self.h_pool=[]\n",
        "        \n",
        "        global_step = tf.Variable(0, trainable=False)\n",
        "        starter_learning_rate = param_lambda\n",
        "        learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 1000, 0.85, staircase=True)\n",
        "\n",
        "        \n",
        "        self.x_input= tf.reshape(self.x, [-1, 128, seq_len*2, 1])\n",
        "        print (self.x_input.shape)\n",
        "        self.layer_input=[]\n",
        "        self.layer_input.append(self.x_input)\n",
        "        #print (self.layer_input[-1].shape)\n",
        "        \n",
        "        for i in range(len(conv_shape)):\n",
        "            self.W_conv.append(self.weight_variable(conv_shape[i]))\n",
        "            self.b_conv.append(self.bias_variable([conv_shape[i][-1]]))\n",
        "\n",
        "            self.h_conv.append(tf.nn.relu(self.conv2d(self.layer_input[-1], self.W_conv[-1]) + self.b_conv[-1]))\n",
        "            self.layer_input.append(self.max_pool_shape(self.h_conv[-1]))\n",
        "            #print (self.layer_input[-1].shape)\n",
        "        \n",
        "        fc_input_shape=[]\n",
        "        a=1\n",
        "        for b in self.layer_input[-1].shape[1:]:\n",
        "            a*=int(b)\n",
        "        fc_input_shape.append(a)\n",
        "        \n",
        "        self.W_fc=[]\n",
        "        self.b_fc=[]\n",
        "        self.h_pool_flat=[]\n",
        "        \n",
        "        \n",
        "        for i in range(len(fc_shape[:-1])):\n",
        "            \n",
        "            self.W_fc.append(self.weight_variable([fc_input_shape[-1], fc_shape[i]]))\n",
        "            self.b_fc.append(self.bias_variable([fc_shape[i]]))\n",
        "\n",
        "            self.h_pool_flat.append(tf.reshape(self.layer_input[-1], [-1, fc_input_shape[-1]]))\n",
        "            self.layer_input.append(tf.nn.relu(tf.matmul(self.h_pool_flat[-1], self.W_fc[-1]) + self.b_fc[-1]))\n",
        "            \n",
        "            fc_input_shape.append(fc_shape[i])\n",
        "            #self.keep_prob = tf.placeholder(tf.float32)\n",
        "            #self.h_fc1_drop = tf.nn.dropout(self.h_fc1, self.keep_prob)\n",
        "\n",
        "        self.W_fc.append(self.weight_variable([fc_input_shape[-1], fc_shape[-1]]))\n",
        "        self.b_fc.append(self.bias_variable([fc_shape[-1]]))\n",
        "        self.y_conv = tf.matmul(self.layer_input[-1], self.W_fc[-1]) + self.b_fc[-1]\n",
        "\n",
        "        self.l2=sum([param_lambda*tf.nn.l2_loss(x) for pom in [self.W_conv,self.W_fc] for x in pom])\n",
        "\n",
        "        self.cross_entropy = tf.reduce_mean(\n",
        "            tf.nn.softmax_cross_entropy_with_logits(labels=self.y_, logits=self.y_conv))+self.l2\n",
        "        self.train_step = tf.train.AdamOptimizer(learning_rate)\n",
        "        \n",
        "        self.learning_step = self.train_step.minimize(self.cross_entropy, global_step=global_step)\n",
        "\n",
        "        \n",
        "        correct_prediction = tf.equal(tf.argmax(self.y_conv, 1), tf.argmax(self.y_, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def train(self):\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            self.data.make_batches()\n",
        "            for i in range(10*self.data.num_batches):\n",
        "                batch = self.data.get_batch()\n",
        "                sess.run(self.learning_step,feed_dict={self.x: batch[0], self.y_: batch[1]})\n",
        "                if i%self.data.num_batches==0:\n",
        "                    acc= self.accuracy.eval(feed_dict={self.x: batch[0], self.y_: batch[1]})\n",
        "                    print (acc, sess.run(self.train_step._lr))\n",
        "                   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wONyJAPJ5Zh4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "f58c353c-b158-4fce-fe5a-79798566541b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527577249935,
          "user_tz": -120,
          "elapsed": 20432,
          "user": {
            "displayName": "Fran Varga",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105985820695936304708"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ext_data=Data()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 / 399\n",
            "10 / 399\n",
            "20 / 399\n",
            "30 / 399\n",
            "40 / 399\n",
            "50 / 399\n",
            "60 / 399\n",
            "70 / 399\n",
            "80 / 399\n",
            "90 / 399\n",
            "100 / 399\n",
            "110 / 399\n",
            "120 / 399\n",
            "130 / 399\n",
            "140 / 399\n",
            "150 / 399\n",
            "160 / 399\n",
            "170 / 399\n",
            "180 / 399\n",
            "190 / 399\n",
            "200 / 399\n",
            "210 / 399\n",
            "220 / 399\n",
            "230 / 399\n",
            "240 / 399\n",
            "250 / 399\n",
            "260 / 399\n",
            "270 / 399\n",
            "280 / 399\n",
            "290 / 399\n",
            "300 / 399\n",
            "310 / 399\n",
            "320 / 399\n",
            "330 / 399\n",
            "340 / 399\n",
            "350 / 399\n",
            "360 / 399\n",
            "370 / 399\n",
            "380 / 399\n",
            "390 / 399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4UsHecIJslVC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "convo_network=ConvNet(ext_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2gOj5F9_MJI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "358fe843-d91d-45d1-a323-c069a0a4415f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527577610371,
          "user_tz": -120,
          "elapsed": 3127,
          "user": {
            "displayName": "Fran Varga",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105985820695936304708"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "convo_network.data.equalize_classes()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "725488\n",
            "1027337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UuSHZqHV5U3G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f3ad91aa-e1c1-4100-c004-f76eaff1e2f7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527577611310,
          "user_tz": -120,
          "elapsed": 757,
          "user": {
            "displayName": "Fran Varga",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105985820695936304708"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for x in convo_network.data.data_label_dict.keys():\n",
        "    print (x,len(convo_network.data.data_label_dict[x]))\n",
        "print (convo_network.data.data.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR 3381\n",
            "CALL 57134\n",
            "IF 39936\n",
            "ELSE 8921\n",
            "WHILE 1943\n",
            "DO 173\n",
            "SWITCH 540\n",
            "FUNCTION 9762\n",
            "(881345, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vml9Z_oI5e63",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "851aaab9-df07-42dd-c1fe-1e4df9ba60bb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527577919865,
          "user_tz": -120,
          "elapsed": 306460,
          "user": {
            "displayName": "Fran Varga",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105985820695936304708"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "convo_network.convolution_graph(conv_shape=[[128,5,1,8]],fc_shape=[10,8], param_lambda=1e-4)\n",
        "convo_network.data.set_batch_size(512)\n",
        "convo_network.train()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 128, 16, 1)\n",
            "0.14257812 1e-04\n",
            "0.7128906 7.225e-05\n",
            "0.8222656 5.2200627e-05\n",
            "0.8359375 3.771496e-05\n",
            "0.8496094 2.7249056e-05\n",
            "0.8535156 1.9687444e-05\n",
            "0.8535156 1.4224181e-05\n",
            "0.8671875 1.027697e-05\n",
            "0.84375 7.4251116e-06\n",
            "0.8613281 5.364643e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8G5k0T4I6sob",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}