{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation\n",
    "class Data:\n",
    "    def __init__(self,source=\"/C_bytecode_analysis/output\", seq_len=8):\n",
    "        self.seq_len=seq_len\n",
    "        self.home=os.getenv(\"HOME\")\n",
    "        self.source=source\n",
    "        self.data=[]\n",
    "        self.keywords=[\"FOR\",\"CALL\",\"IF\",\"ELSE\",\"WHILE\",\"DO\",\"SWITCH\",\"FUNCTION\"]\n",
    "        self.number_of_lines=0\n",
    "        self.data_label_dict={}\n",
    "        for x in self.keywords:\n",
    "            self.data_label_dict[x]=[]\n",
    "        offset=0\n",
    "        for filename in glob.glob(os.path.join(self.home+self.source,'*.labeled_addresses')):\n",
    "            #print (filename)\n",
    "            with open(filename) as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    line=line.strip().split(\"\\t\")\n",
    "                    if len(line)==3:\n",
    "                        func_name=line[0]\n",
    "                        classes=line[1]\n",
    "                        number_of_lines=int(line[2])\n",
    "                        label_list=[]\n",
    "                        offset=len(self.data)\n",
    "                        #print (func_name, classes, number_of_lines)\n",
    "                    else:\n",
    "                        #if len(line)<2:\n",
    "                        #    continue\n",
    "                        #address = line[0]\n",
    "                        bytecode = line[1].strip()\n",
    "                        #instruction = line[2].strip()\n",
    "                        #source_line = int(line[3])\n",
    "                        #source_file = line[4]\n",
    "                        labels = line[5:]\n",
    "                        label_list.append(labels)\n",
    "                        #print (address,bytecode,instruction,source_line,source_file,labels)\n",
    "                        indexes= (str(bytecode))[2:4]\n",
    "                        if len(bytecode)<=10:\n",
    "                            indexes+=str(bytecode)[4:min(len(bytecode),10)]\n",
    "                            indexes+=\"g\"*(10-len(bytecode))\n",
    "                        else:\n",
    "                            indexes+=(str(bytecode))[4:10]\n",
    "                        new=[]\n",
    "                        for x in indexes:\n",
    "                                pom=[0]*16\n",
    "                                if x!=\"g\":\n",
    "                                    pom[int(x,16)]=1\n",
    "                                new.extend(pom)\n",
    "                        self.data.append(np.array(new))\n",
    "                        number_of_lines-=1\n",
    "                        if number_of_lines==0:\n",
    "                            cur=[]\n",
    "                            counter={}\n",
    "                            start_dict={}\n",
    "                            i=-1\n",
    "                            for labels in label_list:\n",
    "                                i+=1\n",
    "                                for label in labels:\n",
    "                                    if label not in cur:\n",
    "                                        cur.append(label)\n",
    "                                        counter[label]=1\n",
    "                                        start_dict[label]=i\n",
    "                                    else:\n",
    "                                        counter[label]+=1\n",
    "                            for label in counter.keys():\n",
    "                                self.data_label_dict[label.split(\"_\")[0]].append((start_dict[label]+offset,counter[label]))\n",
    "            #break\n",
    "        self.data=np.array(self.data)\n",
    "        self.labels_with_length=[]\n",
    "        for x in self.data_label_dict.keys():\n",
    "            cl=self.keywords.index(x)\n",
    "            for y in self.data_label_dict[x]:\n",
    "                self.labels_with_length.append([cl,y[0],y[1]])\n",
    "        self.labels_with_length=np.array(self.labels_with_length)\n",
    "                \n",
    "    def make_batches(self, size=50):\n",
    "        perm=np.random.permutation(len(self.labels_with_length))\n",
    "        self.y_l_batches=[]\n",
    "        pom=self.labels_with_length[perm]\n",
    "        for i in range(int(len(perm)/size)):\n",
    "            self.y_l_batches.append(pom[i*size:i*size+size])\n",
    "        self.y_l_batches=np.array(self.y_l_batches)\n",
    "        self.num_batches=len(self.y_l_batches)\n",
    "        self.current_batch_index=0\n",
    "        self.size=size\n",
    "        \n",
    "    def get_batch(self):\n",
    "        seq_len=self.seq_len\n",
    "        y_l_batch=self.y_l_batches[self.current_batch_index]\n",
    "        pom=[self.data[i[1]:i[1]+i[2]] for i in y_l_batch]\n",
    "        for i in range(len(pom)):\n",
    "            if len(pom[i])>=seq_len*2:\n",
    "                #print (len(pom[i]))\n",
    "                pom[i]=np.vstack((pom[i][:seq_len],pom[i][-seq_len:]))\n",
    "                #print (len(pom[i]))\n",
    "                #print (\"----\")\n",
    "            else:\n",
    "                pom[i]=np.vstack([pom[i],np.array([np.zeros(128) for j in range(seq_len*2-len(pom[i]))])])\n",
    "        x=np.array(pom)\n",
    "        pom=np.array(y_l_batch[:,0])\n",
    "        y=np.eye(8)[pom]\n",
    "        self.current_batch_index+=1\n",
    "        if self.current_batch_index==self.num_batches:\n",
    "            self.make_batches()\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    @staticmethod\n",
    "    def weight_variable(shape):\n",
    "      initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "      return tf.Variable(initial)\n",
    "    \n",
    "    @staticmethod\n",
    "    def bias_variable(shape):\n",
    "      initial = tf.constant(0.1, shape=shape)\n",
    "      return tf.Variable(initial)\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv2d(x, W):\n",
    "      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "    @staticmethod\n",
    "    def max_pool_shape(x, shape=[1,1,2,1]):\n",
    "      return tf.nn.max_pool(x, ksize=shape,\n",
    "                            strides=shape, padding='VALID')\n",
    "\n",
    "    def convolution_graph(self,conv_shape=[[5,5,1,16],[5,5,16,32]],fc_shape=[512,8], param_lambda=0.01, seq_len=8):\n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, seq_len*2, 128], name=\"x\")\n",
    "        self.y_ = tf.placeholder(tf.float32, shape=[None, 8], name=\"y_\")\n",
    "        self.W_conv=[]\n",
    "        self.b_conv=[]\n",
    "        self.h_conv=[]\n",
    "        self.h_pool=[]\n",
    "        \n",
    "        self.x_input= tf.reshape(self.x, [-1, 128, seq_len*2, 1])\n",
    "        print (self.x_input.shape)\n",
    "        self.layer_input=[]\n",
    "        self.layer_input.append(self.x_input)\n",
    "        #print (self.layer_input[-1].shape)\n",
    "        \n",
    "        for i in range(len(conv_shape)):\n",
    "            self.W_conv.append(self.weight_variable(conv_shape[i]))\n",
    "            self.b_conv.append(self.bias_variable([conv_shape[i][-1]]))\n",
    "\n",
    "            self.h_conv.append(tf.nn.relu(self.conv2d(self.layer_input[-1], self.W_conv[-1]) + self.b_conv[-1]))\n",
    "            self.layer_input.append(self.max_pool_shape(self.h_conv[-1]))\n",
    "            #print (self.layer_input[-1].shape)\n",
    "        \n",
    "        fc_input_shape=[]\n",
    "        a=1\n",
    "        for b in self.layer_input[-1].shape[1:]:\n",
    "            a*=int(b)\n",
    "        fc_input_shape.append(a)\n",
    "        \n",
    "        self.W_fc=[]\n",
    "        self.b_fc=[]\n",
    "        self.h_pool_flat=[]\n",
    "        \n",
    "        \n",
    "        for i in range(len(fc_shape[:-1])):\n",
    "            \n",
    "            self.W_fc.append(self.weight_variable([fc_input_shape[-1], fc_shape[i]]))\n",
    "            self.b_fc.append(self.bias_variable([fc_shape[i]]))\n",
    "\n",
    "            self.h_pool_flat.append(tf.reshape(self.layer_input[-1], [-1, fc_input_shape[-1]]))\n",
    "            self.layer_input.append(tf.nn.relu(tf.matmul(self.h_pool_flat[-1], self.W_fc[-1]) + self.b_fc[-1]))\n",
    "            \n",
    "            fc_input_shape.append(fc_shape[i])\n",
    "            #self.keep_prob = tf.placeholder(tf.float32)\n",
    "            #self.h_fc1_drop = tf.nn.dropout(self.h_fc1, self.keep_prob)\n",
    "\n",
    "        self.W_fc.append(self.weight_variable([fc_input_shape[-1], fc_shape[-1]]))\n",
    "        self.b_fc.append(self.bias_variable([fc_shape[-1]]))\n",
    "        self.y_conv = tf.matmul(self.layer_input[-1], self.W_fc[-1]) + self.b_fc[-1]\n",
    "\n",
    "        self.l2=sum([param_lambda*tf.nn.l2_loss(x) for pom in [self.W_conv,self.W_fc] for x in pom])\n",
    "\n",
    "        self.cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(labels=self.y_, logits=self.y_conv))+self.l2\n",
    "        self.train_step = tf.train.AdamOptimizer(1e-4).minimize(self.cross_entropy)\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.y_conv, 1), tf.argmax(self.y_, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "    def train(self):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            self.data.make_batches()\n",
    "            for i in range(100*self.data.num_batches):\n",
    "                batch = self.data.get_batch()\n",
    "                if i%self.data.num_batches==0:\n",
    "                    acc= self.accuracy.eval(feed_dict={self.x: batch[0], self.y_: batch[1]})\n",
    "                    print (acc)\n",
    "                sess.run(self.train_step,feed_dict={self.x: batch[0], self.y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-40989adcd25a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_label_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_label_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "for x in data.data_label_dict.keys():\n",
    "    print (x,len(data.data_label_dict[x]))\n",
    "print (data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 16, 1)\n",
      "0.2\n",
      "0.66\n",
      "0.74\n",
      "0.7\n",
      "0.88\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c4b50a6b7be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconvo_network\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconvo_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolution_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfc_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconvo_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-54eca39443f9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convo_network=ConvNet(Data())\n",
    "convo_network.convolution_graph(conv_shape=[[128,5,1,8]],fc_shape=[10,8], param_lambda=0.01)\n",
    "convo_network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
